{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: tensorflow_datasets\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: emnist in /opt/conda/lib/python3.10/site-packages (0.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from emnist) (4.64.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from emnist) (1.23.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from emnist) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->emnist) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->emnist) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->emnist) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->emnist) (3.4)\n",
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.9.2-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting etils[enp,epath]>=0.9.0\n",
      "  Downloading etils-1.3.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (1.4.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (1.14.1)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (8.1.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (5.9.2)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (2.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (4.64.1)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.13.1-py3-none-any.whl (28 kB)\n",
      "Collecting dm-tree\n",
      "  Downloading dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (1.23.3)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting array-record\n",
      "  Downloading array_record-0.2.0-py310-none-any.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (4.21.12)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (2.28.1)\n",
      "Requirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (5.10.0)\n",
      "Requirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (3.9.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.11)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.59.0-py2.py3-none-any.whl (223 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21486 sha256=94dcdb67f3082e713e796fe84893068c71fb327944c4d31e373749e819626f33\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/76/40/54/417a4d64a01b61b247658d83597e1dc83c3de01fc0cef44972\n",
      "Successfully built promise\n",
      "Installing collected packages: dm-tree, toml, promise, googleapis-common-protos, etils, tensorflow-metadata, array-record, tensorflow_datasets\n",
      "Successfully installed array-record-0.2.0 dm-tree-0.1.8 etils-1.3.0 googleapis-common-protos-1.59.0 promise-2.3 tensorflow-metadata-1.13.1 tensorflow_datasets-4.9.2 toml-0.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow_datasets\n",
    "!pip install emnist\n",
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), info = tfds.load('omniglot', split=['train', 'test'], with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = tfds.as_dataframe(ds_train, info)\n",
    "df_test  = tfds.as_dataframe(ds_test, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19280, 105, 105, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = np.stack(df_train['image'])\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['alphabet', 'alphabet_char_id', 'image', 'label'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alphabet_char_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5234</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6579</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9827</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11257</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13097</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13425</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14849</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14880</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15096</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15524</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16092</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16347</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17100</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17971</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18325</th>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alphabet_char_id  label\n",
       "1464                 23    618\n",
       "1619                 23    618\n",
       "1875                 23    618\n",
       "3247                 23    618\n",
       "4126                 23    618\n",
       "5234                 23    618\n",
       "6579                 23    618\n",
       "9827                 23    618\n",
       "11257                23    618\n",
       "13097                23    618\n",
       "13425                23    618\n",
       "14849                23    618\n",
       "14880                23    618\n",
       "15096                23    618\n",
       "15524                23    618\n",
       "16092                23    618\n",
       "16347                23    618\n",
       "17100                23    618\n",
       "17971                23    618\n",
       "18325                23    618"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['alphabet_char_id', 'label']].loc[np.where((df_train['alphabet'] == 27) & (df_train['alphabet_char_id'] == 23))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Data handling general functions '''\n",
    "\n",
    "def separate_fewshot(test_images, test_labels, n=1):\n",
    "    oneshot_data = []\n",
    "    classify_data = []\n",
    "    for label in np.unique(test_labels):\n",
    "        for num in np.random.choice(np.where(test_labels == label)[0], n, False):\n",
    "            oneshot_data.append(num)\n",
    "    temp = set(oneshot_data)\n",
    "    for i in range(len(test_labels)):\n",
    "        if not i in temp: classify_data.append(i)\n",
    "    oneshot_images = test_images[oneshot_data]\n",
    "    oneshot_labels = test_labels[oneshot_data]\n",
    "    classify_images = test_images[classify_data]\n",
    "    classify_labels = test_labels[classify_data]\n",
    "    return oneshot_images, oneshot_labels, classify_images, classify_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Functions with linear methods '''\n",
    "\n",
    "def test_PCA(train_images, train_labels, oneshot_images, oneshot_labels, classify_images, classify_labels, \n",
    "             n, n_components = 32, verbose=False, train=1):\n",
    "    \n",
    "    if verbose: print(\"======= PCA method: Training and evaluating ... =======\")\n",
    "    if verbose: print(\"Learning background ...\")\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X=train_images)\n",
    "\n",
    "    if verbose: print(\"Vectorizing ...\")\n",
    "    oneshot_images = pca.transform(oneshot_images)\n",
    "    classify_images = pca.transform(classify_images)\n",
    "\n",
    "    if verbose: print(\"Learning oneshot ...\")\n",
    "    nn = min(train, 5)\n",
    "    neigh = KNeighborsClassifier(n_neighbors = nn)\n",
    "    neigh.fit(classify_images, classify_labels)\n",
    "\n",
    "    if verbose: print(\"Predicting ...\")\n",
    "    pred = neigh.predict(oneshot_images)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Accuracy: \", np.sum(pred == oneshot_labels)/len(oneshot_labels))\n",
    "        print(\"======= PCA method: Finished =======\")\n",
    "\n",
    "    return np.sum(pred == classify_labels)/len(classify_labels)\n",
    "\n",
    "def test_LDA(train_images, train_labels, oneshot_images, oneshot_labels, classify_images, classify_labels, \n",
    "             n, n_components = 20, verbose=True, train=1):\n",
    "    \n",
    "    if verbose: print(\"======= LDA method: Training and evaluating ... =======\")\n",
    "    if verbose: print(\"Learning background ...\")\n",
    "    lda = LDA(n_components=n_components)\n",
    "    lda.fit(X=train_images, y = train_labels)\n",
    "\n",
    "    if verbose: print(\"Vectorizing ...\")\n",
    "    oneshot_images = lda.transform(oneshot_images)\n",
    "    classify_images = lda.transform(classify_images)\n",
    "\n",
    "    if verbose: print(\"Learning oneshot ...\")\n",
    "    nn = min(train, 5)\n",
    "    neigh = KNeighborsClassifier(n_neighbors = nn)\n",
    "    neigh.fit(classify_images, classify_labels)\n",
    "\n",
    "    if verbose: print(\"Predicting ...\")\n",
    "    pred = neigh.predict(oneshot_images)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Accuracy: \", np.sum(pred == oneshot_labels)/len(oneshot_labels))\n",
    "        print(\"======= LDA method: Finished =======\")\n",
    "\n",
    "    return np.sum(pred == classify_labels)/len(classify_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in df_train['image']:\n",
    "    assert(image.shape == (105, 105, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1\n",
    "train_images, train_labels = np.stack(df_train['image']).reshape(-1, 105 * 105 * 3), df_train['label'].to_numpy()\n",
    "test_images, test_labels  = np.stack(df_test['image']).reshape(-1, 105 * 105 * 3), df_test['label'].to_numpy()\n",
    "oneshot_images, oneshot_labels, \\\n",
    "    classify_images, classify_labels = separate_fewshot(test_images, test_labels, n = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= PCA method: Training and evaluating ... =======\n",
      "Learning background ...\n",
      "Vectorizing ...\n",
      "Learning oneshot ...\n",
      "Predicting ...\n",
      "Accuracy:  0.3171471927162367\n",
      "======= PCA method: Finished =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64/3493122262.py:27: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  return np.sum(pred == classify_labels)/len(classify_labels)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_PCA(train_images, train_labels, oneshot_images, oneshot_labels, classify_images, classify_labels, n = N, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = df_train['label'].unique()\n",
    "subsample_index = []\n",
    "c = 4\n",
    "for label in unique_labels:\n",
    "    for ind in np.random.choice(np.where(df_train['label'] == label)[0], c, False):\n",
    "        subsample_index.append(ind)\n",
    "subsample_index = np.array(subsample_index)\n",
    "train_images_lda = train_images[subsample_index]\n",
    "train_labels_lda = train_labels[subsample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3856, 33075)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_lda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= LDA method: Training and evaluating ... =======\n",
      "Learning background ...\n",
      "Vectorizing ...\n",
      "Learning oneshot ...\n",
      "Predicting ...\n",
      "Accuracy:  0.01669195751138088\n",
      "======= LDA method: Finished =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64/36379175.py:53: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  return np.sum(pred == classify_labels)/len(classify_labels)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_LDA(train_images_lda, train_labels_lda, oneshot_images, oneshot_labels, classify_images, classify_labels, n = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
