{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bd6531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.keras as keras\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Input, Lambda, Conv2D,Conv2DTranspose, MaxPooling2D, BatchNormalization, Dense, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc089630",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), info = tfds.load('omniglot', split=['train', 'test'], with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e09663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = tfds.as_dataframe(ds_train, info)\n",
    "df_test  = tfds.as_dataframe(ds_test, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2bad4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(images, size, to_grayscale=True):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        resized_image = cv2.resize(img, (size, size))\n",
    "        if to_grayscale:\n",
    "            resized_image= cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "        resized_images.append(resized_image)\n",
    "    return np.array(resized_images)\n",
    "\n",
    "def parse_omniglot_dataframe(df, img_size=56, reshape=False):\n",
    "    images = resize_images(df['image'], img_size)\n",
    "    if reshape:\n",
    "        images = images.reshape(-1, img_size * img_size)\n",
    "    else:\n",
    "        images.reshape(-1, img_size, img_size)\n",
    "    labels = df['label'].to_numpy()\n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b72b2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_encoder(w, h, encoding_size):\n",
    "    return Sequential([\n",
    "        Conv2D(16, (3, 3), input_shape=(w, h, 1), activation='relu', kernel_regularizer='l2'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=2, strides=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(32, (3, 3), kernel_regularizer='l2'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=2, strides=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Flatten(),\n",
    "        \n",
    "        Dense(encoding_size),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4af46c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    This layer is responsible for computing the distance between the anchor\n",
    "    embedding and the positive embedding, and the anchor embedding and the\n",
    "    negative embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
    "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
    "        return (ap_distance, an_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bd4f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def siamese_net_for_triplet_loss(w, h, encoding_size):\n",
    "    anchor_input = layers.Input(name=\"anchor\", shape=(w, h, 1))\n",
    "    positive_input = layers.Input(name=\"positive\", shape=(w, h, 1))\n",
    "    negative_input = layers.Input(name=\"negative\", shape=(w, h, 1))\n",
    "\n",
    "    encoder = cnn_encoder(w, h, encoding_size)\n",
    "\n",
    "    distances = DistanceLayer()(\n",
    "        encoder(anchor_input),\n",
    "        encoder(positive_input),\n",
    "        encoder(negative_input),\n",
    "    )\n",
    "\n",
    "    siamese_network = Model(\n",
    "        inputs=[anchor_input, positive_input, negative_input], outputs=distances\n",
    "    )\n",
    "\n",
    "    return siamese_network, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2be7621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(Model):\n",
    "    \"\"\"\n",
    "    The Siamese Network model with a custom training and testing loops.\n",
    "\n",
    "    Computes the triplet loss using the three embeddings produced by the\n",
    "    Siamese Network.\n",
    "\n",
    "    The triplet loss is defined as:\n",
    "       L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, siamese_network, margin=5):\n",
    "        super().__init__()\n",
    "        self.siamese_network = siamese_network\n",
    "        self.margin = margin\n",
    "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # GradientTape is a context manager that records every operation that\n",
    "        # you do inside. We are using it here to compute the loss so we can get\n",
    "        # the gradients and apply them using the optimizer specified in\n",
    "        # `compile()`.\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "\n",
    "        # Storing the gradients of the loss function with respect to the\n",
    "        # weights/parameters.\n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "\n",
    "        # Applying the gradients on the model using the specified optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.siamese_network.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Let's update and return the training loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result(), \"pdistance\": self.siamese_network(data)[0], \"ndistance\": self.siamese_network(data)[1]}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "\n",
    "        # Let's update and return the loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        # The output of the network is a tuple containing the distances\n",
    "        # between the anchor and the positive example, and the anchor and\n",
    "        # the negative example.\n",
    "        ap_distance, an_distance = self.siamese_network(data)\n",
    "\n",
    "        # Computing the Triplet Loss by subtracting both distances and\n",
    "        # making sure we don't get a negative value.\n",
    "        loss = ap_distance - an_distance\n",
    "        loss = tf.maximum(loss + self.margin, 0.0)\n",
    "        return loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3aba5f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_by_label(train_images, train_labels, label):\n",
    "    return train_images[np.random.choice(np.where(train_labels == label)[0], 1, replace=False)[0]]\n",
    "\n",
    "def get_triplets(train_images, train_labels, batch_size, w, h):\n",
    "    triplets = [np.zeros((batch_size, w, h)) for _ in range(3)]\n",
    "    labels = np.unique(train_labels)\n",
    "    for i in range(batch_size):\n",
    "        class1, class2 = np.random.choice(labels, 2, replace=False)\n",
    "        assert(class1 != class2)\n",
    "        triplets[0][i] = get_image_by_label(train_images, train_labels, class1)\n",
    "        triplets[1][i] = get_image_by_label(train_images, train_labels, class1)\n",
    "        triplets[2][i] = get_image_by_label(train_images, train_labels, class2)\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58fb1526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_fewshot(test_images, test_labels, n_shots):\n",
    "    fewshot_pick = []\n",
    "    val_pick = []\n",
    "    for label in np.unique(test_labels):\n",
    "        for i in np.random.choice(np.where(test_labels == label)[0], n_shots, False):\n",
    "            fewshot_pick.append(i)\n",
    "    temp = set(fewshot_pick)\n",
    "    for i in range(len(test_labels)):\n",
    "        if not i in temp:\n",
    "            val_pick.append(i)\n",
    "    fewshot_images = test_images[fewshot_pick]\n",
    "    fewshot_labels = test_labels[fewshot_pick]\n",
    "    val_images = test_images[val_pick]\n",
    "    val_labels = test_labels[val_pick]\n",
    "    return fewshot_images, fewshot_labels, val_images, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "922fb5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fewshot(encoder, n_shots, fewshot_images, fewshot_labels):\n",
    "    return KNeighborsClassifier(n_neighbors=min(n_shots, 5)).fit(encoder(fewshot_images), fewshot_labels)\n",
    "\n",
    "def trains_fewshot(encoder, ns_shots, test_images, test_labels, verbose=True):\n",
    "    accuracies = [None] * len(ns_shots)\n",
    "    for i, n_shots in enumerate(ns_shots):\n",
    "        if verbose: print(f'Learning {n_shots}-shot and predicting...')\n",
    "        fewshot_images, fewshot_labels, val_images, val_labels = separate_fewshot(test_images, test_labels, n_shots)\n",
    "        classifier = train_fewshot(encoder, n_shots, fewshot_images, fewshot_labels)\n",
    "        pred = classifier.predict(encoder(val_images))\n",
    "        accuracies[i] = np.sum(pred == val_labels) / val_labels.shape[0]\n",
    "        if verbose:\n",
    "            print(f'Accuracy for {n_shots}-shot: {accuracies[i]}')\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6dc27beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_SN_TL(df_train, df_test, img_size=56, ns_shots=[1, 3, 5], n_iterations=2000, batch_size=10, encoding_size=32, verbose=True):\n",
    "    train_images, train_labels = parse_omniglot_dataframe(df_train, img_size)\n",
    "    test_images, test_labels = parse_omniglot_dataframe(df_test, img_size)\n",
    "\n",
    "    if verbose: print(\"======= Siamese network with triplet loss method: Training and evaluating... =======\")\n",
    "    if verbose: print(\"Learning background...\")\n",
    "\n",
    "    siamese_network, encoder = siamese_net_for_triplet_loss(img_size, img_size, encoding_size)\n",
    "    siamese_model = SiameseModel(siamese_network)\n",
    "    siamese_model.compile(optimizer=optimizers.Adam())\n",
    "    for _ in range(n_iterations):\n",
    "        siamese_model.fit(get_triplets(train_images, train_labels, batch_size, img_size, img_size))\n",
    "\n",
    "    accuracies = trains_fewshot(encoder, ns_shots, test_images, test_labels)\n",
    "    \n",
    "    if verbose: print(\"======= Siamese network with triplet loss method: Finished =======\")\n",
    "\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d774a6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Siamese network with triplet loss method: Training and evaluating... =======\n",
      "Learning background...\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_4/sequential_4/conv2d_8/Relu' defined at (most recent call last):\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_7273/2370511182.py\", line 1, in <module>\n      test_SN_TL(df_train, df_test)\n    File \"/tmp/ipykernel_7273/3196673456.py\", line 12, in test_SN_TL\n      siamese_model.fit(get_triplets(train_images, train_labels, batch_size, img_size, img_size))\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/tmp/ipykernel_7273/202769682.py\", line 27, in train_step\n      loss = self._compute_loss(data)\n    File \"/tmp/ipykernel_7273/202769682.py\", line 53, in _compute_loss\n      ap_distance, an_distance = self.siamese_network(data)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 321, in call\n      return self.activation(outputs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/backend.py\", line 5396, in relu\n      x = tf.nn.relu(x)\nNode: 'model_4/sequential_4/conv2d_8/Relu'\nDNN library is not found.\n\t [[{{node model_4/sequential_4/conv2d_8/Relu}}]] [Op:__inference_train_function_136173]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_SN_TL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 12\u001b[0m, in \u001b[0;36mtest_SN_TL\u001b[0;34m(df_train, df_test, img_size, ns_shots, n_iterations, batch_size, encoding_size, verbose)\u001b[0m\n\u001b[1;32m     10\u001b[0m siamese_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam())\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[0;32m---> 12\u001b[0m     \u001b[43msiamese_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_triplets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m trains_fewshot(encoder, ns_shots, test_images, test_labels)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m======= Siamese network with triplet loss method: Finished =======\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_4/sequential_4/conv2d_8/Relu' defined at (most recent call last):\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_7273/2370511182.py\", line 1, in <module>\n      test_SN_TL(df_train, df_test)\n    File \"/tmp/ipykernel_7273/3196673456.py\", line 12, in test_SN_TL\n      siamese_model.fit(get_triplets(train_images, train_labels, batch_size, img_size, img_size))\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/tmp/ipykernel_7273/202769682.py\", line 27, in train_step\n      loss = self._compute_loss(data)\n    File \"/tmp/ipykernel_7273/202769682.py\", line 53, in _compute_loss\n      ap_distance, an_distance = self.siamese_network(data)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 321, in call\n      return self.activation(outputs)\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/users/eleves-b/2021/the.nguyen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/backend.py\", line 5396, in relu\n      x = tf.nn.relu(x)\nNode: 'model_4/sequential_4/conv2d_8/Relu'\nDNN library is not found.\n\t [[{{node model_4/sequential_4/conv2d_8/Relu}}]] [Op:__inference_train_function_136173]"
     ]
    }
   ],
   "source": [
    "test_SN_TL(df_train, df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
