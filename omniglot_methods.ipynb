{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emnist in /users/eleves-a/2021/moreira.machado/.local/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: numpy in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from emnist) (1.23.5)\n",
      "Requirement already satisfied: requests in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from emnist) (2.29.0)\n",
      "Requirement already satisfied: tqdm in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from emnist) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from requests->emnist) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from requests->emnist) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from requests->emnist) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from requests->emnist) (2023.5.7)\n",
      "Requirement already satisfied: tensorflow_datasets in /users/eleves-a/2021/moreira.machado/.local/lib/python3.9/site-packages (4.9.2)\n",
      "Requirement already satisfied: absl-py in /users/eleves-a/2021/moreira.machado/.local/lib/python3.9/site-packages (from tensorflow_datasets) (1.4.0)\n",
      "Requirement already satisfied: array-record in /users/eleves-a/2021/moreira.machado/.local/lib/python3.9/site-packages (from tensorflow_datasets) (0.2.0)\n",
      "Requirement already satisfied: click in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (8.1.3)\n",
      "Requirement already satisfied: dm-tree in /users/eleves-a/2021/moreira.machado/.local/lib/python3.9/site-packages (from tensorflow_datasets) (0.1.8)\n",
      "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /users/eleves-a/2021/moreira.machado/.local/lib/python3.9/site-packages (from tensorflow_datasets) (1.3.0)\n",
      "Requirement already satisfied: numpy in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (1.23.5)\n",
      "Requirement already satisfied: promise in /users/eleves-a/2021/moreira.machado/.local/lib/python3.9/site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in /users/eleves-a/2021/moreira.machado/.local/lib/python3.9/site-packages (from tensorflow_datasets) (4.23.1)\n",
      "Requirement already satisfied: psutil in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (5.9.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (2.29.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /users/eleves-a/2021/moreira.machado/.local/lib/python3.9/site-packages (from tensorflow_datasets) (1.13.1)\n",
      "Requirement already satisfied: termcolor in /users/eleves-a/2021/moreira.machado/.local/lib/python3.9/site-packages (from tensorflow_datasets) (2.3.0)\n",
      "Requirement already satisfied: toml in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (4.65.0)\n",
      "Requirement already satisfied: wrapt in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (1.14.1)\n",
      "Requirement already satisfied: importlib_resources in /users/eleves-a/2021/moreira.machado/.local/lib/python3.9/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (5.12.0)\n",
      "Requirement already satisfied: typing_extensions in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (4.5.0)\n",
      "Requirement already satisfied: zipp in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (2023.5.7)\n",
      "Requirement already satisfied: six in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /users/eleves-a/2021/moreira.machado/.local/lib/python3.9/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.59.0)\n",
      "Requirement already satisfied: opencv_python in /users/eleves-a/2021/moreira.machado/.local/lib/python3.9/site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from opencv_python) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /users/eleves-a/2021/moreira.machado/.local/lib/python3.9/site-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: chardet in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (5.1.0)\n",
      "Requirement already satisfied: pandas in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /users/eleves-a/2021/moreira.machado/miniconda3/envs/tf/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip show tensorflow_datasets\n",
    "!pip3 install emnist\n",
    "!pip3 install tensorflow_datasets\n",
    "!pip3 install opencv_python\n",
    "!pip3 install matplotlib\n",
    "!pip3 install chardet\n",
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import emnist\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.keras as keras\n",
    "import sklearn\n",
    "import random\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Input, Lambda, Conv2D,Conv2DTranspose, MaxPooling2D, BatchNormalization, Dense, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import backend as K\n",
    "%matplotlib inline\n",
    "# tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Default GPU Device: /device:GPU:0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), info = tfds.load('omniglot', split=['train', 'test'], with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = tfds.as_dataframe(ds_train, info)\n",
    "df_test  = tfds.as_dataframe(ds_test, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19280, 105, 105, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = np.stack(df_train['image'])\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['alphabet', 'alphabet_char_id', 'image', 'label'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "964"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "shots = 1\n",
    "train_shots = 5\n",
    "classes = 5\n",
    "img_size = 56\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Data handling general functions '''\n",
    "\n",
    "def separate_fewshot(test_images, test_labels, n=1):\n",
    "    oneshot_data = []\n",
    "    classify_data = []\n",
    "    for label in np.unique(test_labels):\n",
    "        for num in np.random.choice(np.where(test_labels == label)[0], n, False):\n",
    "            oneshot_data.append(num)\n",
    "    temp = set(oneshot_data)\n",
    "    for i in range(len(test_labels)):\n",
    "        if not i in temp: classify_data.append(i)\n",
    "    oneshot_images = test_images[oneshot_data]\n",
    "    oneshot_labels = test_labels[oneshot_data]\n",
    "    classify_images = test_images[classify_data]\n",
    "    classify_labels = test_labels[classify_data]\n",
    "    return oneshot_images, oneshot_labels, classify_images, classify_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(images, size, to_grayscale = True):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        resized_image = cv2.resize(img, (size, size))\n",
    "        if to_grayscale:\n",
    "            resized_image= cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "        resized_images.append(resized_image)\n",
    "    return np.array(resized_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_omniglot_dataframe(df, img_size = 56, reshape=True):\n",
    "    images = resize_images(df['image'], img_size)\n",
    "    if reshape:\n",
    "        images = images.reshape(-1, img_size * img_size)\n",
    "    else:\n",
    "        images.reshape(-1, img_size, img_size)\n",
    "        images = images[..., np.newaxis]\n",
    "    labels = df['label'].to_numpy()\n",
    "    data = {}\n",
    "    for label in np.unique(labels):\n",
    "        data[label] = images[np.where(labels == label)]\n",
    "    return (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mini_dataset(\n",
    "        data, labels, batch_size=batch_size, shots=shots, num_classes=classes, img_size=img_size, split=False\n",
    "    ):\n",
    "    temp_labels = np.zeros(shape=(num_classes * shots))\n",
    "    temp_images = np.zeros(shape=(num_classes * shots, img_size, img_size, 1))\n",
    "    if split:\n",
    "        test_labels = np.zeros(shape=(num_classes))\n",
    "        test_images = np.zeros(shape=(num_classes, img_size, img_size, 1))\n",
    "\n",
    "    # Get a random subset of labels from the entire label set.\n",
    "    label_subset = random.choices(labels, k=num_classes)\n",
    "    for class_idx, class_obj in enumerate(label_subset):\n",
    "        # Use enumerated index value as a temporary label for mini-batch in\n",
    "        # few shot learning.\n",
    "        temp_labels[class_idx * shots : (class_idx + 1) * shots] = class_idx\n",
    "        # If creating a split dataset for testing, select an extra sample from each\n",
    "        # label to create the test dataset.\n",
    "        if split:\n",
    "            test_labels[class_idx] = class_idx\n",
    "            images_to_split = random.choices(\n",
    "                data[label_subset[class_idx]], k=shots + 1\n",
    "            )\n",
    "            test_images[class_idx] = images_to_split[-1]\n",
    "            temp_images[\n",
    "                class_idx * shots : (class_idx + 1) * shots\n",
    "            ] = images_to_split[:-1]\n",
    "        else:\n",
    "            # For each index in the randomly selected label_subset, sample the\n",
    "            # necessary number of images.\n",
    "            temp_images[\n",
    "                class_idx * shots : (class_idx + 1) * shots\n",
    "            ] = random.choices(data[label_subset[class_idx]], k=shots)\n",
    "\n",
    "    ind = np.arange(temp_images.shape[0])\n",
    "    ind = np.random.shuffle(ind)\n",
    "    temp_images = temp_images[ind][:batch_size].reshape(-1, img_size, img_size, 1)\n",
    "    temp_labels = temp_labels[ind][:batch_size].reshape(-1)\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices(\n",
    "#         (temp_images.astype(np.float32), temp_labels.astype(np.int32))\n",
    "#     )\n",
    "#     dataset = dataset.shuffle(100).batch(batch_size).repeat(4)\n",
    "    if split:\n",
    "        return temp_images, temp_labels, test_images, test_labels\n",
    "    return temp_images, temp_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 56, 56, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, lbl = parse_omniglot_dataframe(df_test, reshape=False)\n",
    "data[lbl[0]].shape\n",
    "get_mini_dataset(data, lbl)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siamese_net_and_encoder(input_shape, code_size = 0):\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    encoder = Sequential()\n",
    "    encoder.add(Conv2D(64, (10, 10), input_shape=input_shape, activation='relu', kernel_regularizer='l2'))\n",
    "    encoder.add(BatchNormalization())\n",
    "    encoder.add(Activation('relu'))\n",
    "    encoder.add(MaxPooling2D(pool_size=2))\n",
    "    encoder.add(Dropout(0.25))\n",
    "    \n",
    "    encoder.add(Conv2D(128, (7, 7), kernel_regularizer='l2'))\n",
    "    encoder.add(BatchNormalization())\n",
    "    encoder.add(Activation('relu'))\n",
    "    encoder.add(MaxPooling2D(pool_size=2))\n",
    "    encoder.add(Dropout(0.25))\n",
    "    \n",
    "    encoder.add(Conv2D(128, (4, 4), kernel_regularizer='l2'))\n",
    "    encoder.add(BatchNormalization())\n",
    "    encoder.add(Activation('relu'))\n",
    "    encoder.add(MaxPooling2D(pool_size=2))\n",
    "    encoder.add(Dropout(0.25))\n",
    "    #encoder.add(Conv2D(256, (4, 4), kernel_regularizer='l2'))\n",
    "    \n",
    "    encoder.add(Flatten())\n",
    "    \n",
    "    encoder.add(Dense(2048, activation='sigmoid', kernel_regularizer='l2'))\n",
    "    \n",
    "    left_emb = encoder(left_input)\n",
    "    right_emb = encoder(right_input)\n",
    "    \n",
    "    L1_Layer = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))\n",
    "    L1_Dist = L1_Layer([left_emb,right_emb])\n",
    "    OP = Dense(1, activation='sigmoid', kernel_regularizer='l2')(L1_Dist)\n",
    "    \n",
    "    siamese_net = Model(inputs=[left_input, right_input], outputs=OP)\n",
    "    \n",
    "    return siamese_net, encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 56, 56, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 56, 56, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 2048)         1722176     ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 2048)         0           ['sequential[0][0]',             \n",
      "                                                                  'sequential[1][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            2049        ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,724,225\n",
      "Trainable params: 1,723,585\n",
      "Non-trainable params: 640\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_net, encoder = get_siamese_net_and_encoder((img_size, img_size, 1))\n",
    "\n",
    "siamese_net.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_by_label(label, train_images, train_labels):\n",
    "    return train_images[np.random.choice(np.where(train_labels == label)[0], 1, False)[0]]\n",
    "\n",
    "def get_train_data(size, train_images, train_labels, img_size):\n",
    "    targets = np.zeros((size,))\n",
    "    targets[size // 2:] = 1\n",
    "    pairs = [np.zeros((size, img_size, img_size)) for _ in range(2)]\n",
    "    labels = np.unique(train_labels)\n",
    "    for i in range(size):\n",
    "        class1 = np.random.choice(labels, 1)[0]\n",
    "        class2 = class1\n",
    "        if i < size // 2:\n",
    "            while class2 == class1:\n",
    "                class2 = np.random.choice(labels, 1)[0]\n",
    "        pairs[0][i] = get_image_by_label(class1, train_images, train_labels)\n",
    "        pairs[1][i] = get_image_by_label(class2, train_images, train_labels)\n",
    "    return pairs, targets\n",
    "\n",
    "def get_train_batch(train_images, train_labels, n_classes, n_shots, n_support, n_iterations, img_size=56):\n",
    "    labels = np.unique(train_labels)\n",
    "    num_labels = labels.shape[0]\n",
    "    np.random.shuffle(labels)\n",
    "    \n",
    "    x, y = np.zeros((n_classes * n_shots, img_size, img_size)), np.zeros((n_classes * n_support, img_size, img_size))\n",
    "    x_l, y_l = np.zeros(n_classes * n_shots), np.zeros(n_classes * n_support)\n",
    "    \n",
    "    size = n_classes * n_classes * n_shots * n_support\n",
    "    n_iterations = min(n_iterations, (num_labels + n_classes - 1) // n_classes)\n",
    "    \n",
    "    pairs = [[None for _ in range(size * n_iterations)], [None for _ in range(size * n_iterations)]]\n",
    "    target = np.zeros(size * n_iterations)\n",
    "    \n",
    "    cur = 0\n",
    "    for t in range(0, n_iterations * n_classes, n_classes):\n",
    "        classes = labels[t: t + n_classes]\n",
    "        #classes = np.random.choice(labels, n_classes, False)        \n",
    "        for i, c in enumerate(classes):\n",
    "            ind = np.where(train_labels == c)[0]\n",
    "            ind = np.random.choice(ind, n_shots + n_support, False)\n",
    "\n",
    "            x_ind = ind[:n_shots]\n",
    "            x[i * n_shots: (i+1) * n_shots, :] = train_images[x_ind]\n",
    "            x_l[i * n_shots: (i+1) * n_shots] = train_labels[x_ind]\n",
    "\n",
    "            y_ind = ind[n_shots:]\n",
    "            y[i * n_support: (i+1) * n_support, :] = train_images[y_ind]\n",
    "            y_l[i * n_support: (i+1) * n_support] = train_labels[y_ind]\n",
    "        for i, xx in enumerate(x):\n",
    "            if x_l[i] not in classes:\n",
    "                continue\n",
    "            for j, yy in enumerate(y):\n",
    "                if y_l[j] not in classes:\n",
    "                    continue\n",
    "                pairs[0][cur] = xx\n",
    "                pairs[1][cur] = yy\n",
    "                target[cur] = ((x_l[i] == y_l[j]) and (x_l[i] != -1))\n",
    "                cur += 1\n",
    "    pairs[0] = np.array(pairs[0][:cur])\n",
    "    pairs[1] = np.array(pairs[1][:cur])\n",
    "    target = target[:cur]\n",
    "    return pairs, target\n",
    "\n",
    "def visualize_siamese(siamese_net, train_images, train_labels, label1 = 1, label2=2):\n",
    "    x = train_images[np.where(train_labels == label1)[0][:1]]\n",
    "    y = train_images[np.where(train_labels == label2)[0][1:2]]\n",
    "    d = siamese_net.predict([x, y], verbose=0)\n",
    "    fig, axis = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axis[0].axis(\"off\")\n",
    "    axis[1].axis(\"off\")\n",
    "    fig.suptitle(f\"Output {d[0][0]}\")\n",
    "    axis[0].imshow(x[0], cmap='gray')\n",
    "    axis[1].imshow(y[0], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 20\n",
    "num_iterations_alphabet = 1000\n",
    "batch_size = 62\n",
    "evaluateEvery = 200\n",
    "num_shots = 1\n",
    "IMG_SIZE = 56\n",
    "n_support = 5\n",
    "n_classes = 10\n",
    "num_labels = np.unique(train_labels).shape[0]\n",
    "n_iterations = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "242/242 [==============================] - 5s 21ms/step - loss: 0.1772 - accuracy: 0.9935\n",
      "Epoch 2:\n",
      "242/242 [==============================] - 5s 21ms/step - loss: 0.2005 - accuracy: 0.9914\n",
      "Epoch 3:\n",
      "242/242 [==============================] - 5s 21ms/step - loss: 0.2584 - accuracy: 0.9903\n",
      "Epoch 4:\n",
      "242/242 [==============================] - 5s 21ms/step - loss: 0.2909 - accuracy: 0.9864\n",
      "Epoch 5:\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[172], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m         loss \u001b[38;5;241m=\u001b[39m siamese_net\u001b[38;5;241m.\u001b[39mfit(x, y, batch_size\u001b[38;5;241m=\u001b[39mbatch_size,)\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m#if i % evaluateEvery == 0:\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;66;03m#    print('Iteration', i, '- Loss:',loss[0],'- Acc:', round(loss[1], 2))\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrain_one_shot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[172], line 7\u001b[0m, in \u001b[0;36mtrain_one_shot\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m x, y \u001b[38;5;241m=\u001b[39m get_train_batch(train_images, train_labels, n_classes\u001b[38;5;241m=\u001b[39mn_classes, n_shots\u001b[38;5;241m=\u001b[39mnum_shots, n_support\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_iterations\u001b[38;5;241m=\u001b[39mn_iterations, img_size\u001b[38;5;241m=\u001b[39mIMG_SIZE)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#print(\"shapes:\", x[0].shape, x[1].shape, y.shape)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#print(\"sum is:\", np.sum(y), \"should be:\", n_iterations * n_classes * num_shots * n_support)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43msiamese_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "def train_one_shot():\n",
    "    for i in range(1, num_iterations + 1):\n",
    "        print(f\"Epoch {i}:\")\n",
    "        x, y = get_train_batch(train_images, train_labels, n_classes=n_classes, n_shots=num_shots, n_support=5, n_iterations=n_iterations, img_size=IMG_SIZE)\n",
    "        #print(\"shapes:\", x[0].shape, x[1].shape, y.shape)\n",
    "        #print(\"sum is:\", np.sum(y), \"should be:\", n_iterations * n_classes * num_shots * n_support)\n",
    "        loss = siamese_net.fit(x, y, batch_size=batch_size,)\n",
    "        #if i % evaluateEvery == 0:\n",
    "        #    print('Iteration', i, '- Loss:',loss[0],'- Acc:', round(loss[1], 2))\n",
    "train_one_shot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_siamese(siamese_net, train_images, train_labels, label1=63, label2=62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing ...\n",
      "20 380\n",
      "(7600, 56, 56) (7600, 56, 56)\n",
      "Projecting alphabet 1\n",
      "Testing\n",
      "26 494\n",
      "(12844, 56, 56) (12844, 56, 56)\n",
      "Projecting alphabet 6\n",
      "Testing\n",
      "26 494\n",
      "(12844, 56, 56) (12844, 56, 56)\n",
      "Projecting alphabet 7\n",
      "Testing\n",
      "26 494\n",
      "(12844, 56, 56) (12844, 56, 56)\n",
      "Projecting alphabet 8\n",
      "Testing\n",
      "26 494\n",
      "(12844, 56, 56) (12844, 56, 56)\n",
      "Projecting alphabet 9\n",
      "Testing\n",
      "26 494\n",
      "(12844, 56, 56) (12844, 56, 56)\n",
      "Projecting alphabet 18\n",
      "Testing\n",
      "45 855\n",
      "(38475, 56, 56) (38475, 56, 56)\n",
      "Projecting alphabet 19\n",
      "Testing\n",
      "45 855\n",
      "(38475, 56, 56) (38475, 56, 56)\n",
      "Projecting alphabet 23\n",
      "Testing\n",
      "41 779\n",
      "(31939, 56, 56) (31939, 56, 56)\n",
      "Projecting alphabet 28\n",
      "Testing\n",
      "26 494\n",
      "(12844, 56, 56) (12844, 56, 56)\n",
      "Projecting alphabet 29\n",
      "Testing\n",
      "47 893\n",
      "(41971, 56, 56) (41971, 56, 56)\n",
      "Projecting alphabet 33\n",
      "Testing\n",
      "40 760\n",
      "(30400, 56, 56) (30400, 56, 56)\n",
      "Projecting alphabet 34\n",
      "Testing\n",
      "30 570\n",
      "(17100, 56, 56) (17100, 56, 56)\n",
      "Projecting alphabet 36\n",
      "Testing\n",
      "45 855\n",
      "(38475, 56, 56) (38475, 56, 56)\n",
      "Projecting alphabet 39\n",
      "Testing\n",
      "46 874\n",
      "(40204, 56, 56) (40204, 56, 56)\n",
      "Projecting alphabet 40\n",
      "Testing\n",
      "28 532\n",
      "(14896, 56, 56) (14896, 56, 56)\n",
      "Projecting alphabet 42\n",
      "Testing\n",
      "23 437\n",
      "(10051, 56, 56) (10051, 56, 56)\n",
      "Projecting alphabet 44\n",
      "Testing\n",
      "25 475\n",
      "(11875, 56, 56) (11875, 56, 56)\n",
      "Projecting alphabet 46\n",
      "Testing\n",
      "42 798\n",
      "(33516, 56, 56) (33516, 56, 56)\n",
      "Projecting alphabet 47\n",
      "Testing\n",
      "26 494\n",
      "(12844, 56, 56) (12844, 56, 56)\n",
      "Projecting alphabet 49\n",
      "Testing\n",
      "Accuracy:  0.14751217953837553\n",
      "======= NL Autoencoder method: Finished =======\n"
     ]
    }
   ],
   "source": [
    "matches = 0\n",
    "total = 0\n",
    "(test_images, test_labels) = resize_images(df_test['image'], IMG_SIZE), df_test['label'].to_numpy()\n",
    "\n",
    "def get_mode(l):\n",
    "    d = {}\n",
    "    mode = None\n",
    "    count = 0\n",
    "    for i in l:\n",
    "        if i in d:\n",
    "            d[i] += 1\n",
    "        else:\n",
    "            d[i] = 1\n",
    "        if d[i] > count:\n",
    "            mode = i\n",
    "    return mode\n",
    "\n",
    "print(\"Vectorizing ...\")\n",
    "for alphabet in np.unique(df_test['alphabet']):\n",
    "    ind_alphabet = np.where(df_test['alphabet'] == alphabet)[0]\n",
    "    labels = test_labels[ind_alphabet]\n",
    "    images = test_images[ind_alphabet]\n",
    "    os_img, os_label, clas_img, clas_label = separate_fewshot(images, labels, n=num_shots)\n",
    "    \n",
    "    l_os = os_img\n",
    "    l_clas = clas_img\n",
    "    print(len(l_os), len(l_clas))\n",
    "    x, y = [], []\n",
    "    for i, c_i in enumerate(l_clas):\n",
    "        x += [c_i.copy() for _ in range(len(l_os))]\n",
    "        y = [*y, *l_os]\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    print(x.shape, y.shape)\n",
    "    print(f\"Projecting alphabet {alphabet}\")\n",
    "    t = siamese_net.predict([x, y], verbose=0)\n",
    "    print(\"Testing\")\n",
    "    for i in range(len(clas_img)):\n",
    "        arr = t[i * len(os_img): (i + 1) * len(os_img)].reshape(-1)\n",
    "        ind = np.argsort(arr)[-num_shots:]\n",
    "        ind = get_mode(ind)\n",
    "        pred = os_label[ind]\n",
    "        #print(t.shape, ind, pred, clas_label[i])\n",
    "        matches += np.sum(pred == clas_label[i])\n",
    "        total += 1\n",
    "\n",
    "print(\"Accuracy: \", matches/total)\n",
    "print(\"======= NL Autoencoder method: Finished =======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying the encoder with 1 shots\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "28/28 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "28/28 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "0.14910949604664164\n"
     ]
    }
   ],
   "source": [
    "matches = total = 0\n",
    "print(f\"Trying the encoder with {num_shots} shots\")\n",
    "for alphabet in np.unique(df_test['alphabet']):\n",
    "    ind_alphabet = np.where(df_test['alphabet'] == alphabet)[0]\n",
    "    labels = test_labels[ind_alphabet]\n",
    "    images = test_images[ind_alphabet]\n",
    "    os_img, os_label, clas_img, clas_label = separate_fewshot(images, labels, n=num_shots)\n",
    "    \n",
    "    os_img = encoder.predict(os_img)\n",
    "    clas_img = encoder.predict(clas_img)\n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors = num_shots)\n",
    "    neigh.fit(os_img, os_label)\n",
    "    \n",
    "    pred = neigh.predict(clas_img)\n",
    "    matches += np.sum(pred == clas_label)\n",
    "    total += len(clas_label)\n",
    "print(matches/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## total = matches = 0\n",
    "os_img, os_label, clas_img, clas_label = separate_fewshot(test_images, test_labels, n=1)\n",
    "os_img = encoder.predict(os_img)\n",
    "clas_img = encoder.predict(clas_img)\n",
    "\n",
    "#if verbose: print(\"Learning oneshot ...\")\n",
    "#nn = min(train, 5)\n",
    "neigh = KNeighborsClassifier(n_neighbors = 1)\n",
    "neigh.fit(os_img, os_label)\n",
    "\n",
    "#if verbose: print(\"Predicting ...\")\n",
    "pred = neigh.predict(clas_img)\n",
    "\n",
    "matches += np.sum(pred == clas_label)\n",
    "total += len(clas_label)\n",
    "print(matches / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
